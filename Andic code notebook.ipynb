{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Code for the Phonological Complexity in Andic Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants = ['b', 'bː', 'bʷ',\n",
    "              'p', 'pː', \"p'\",\n",
    "              'd', 'dː', 'dʷ', 'dːʷ',\n",
    "              't', 'tː', \"t'\", \"t'ː\", 'tʷ', \"t'ʷ\", 'tsːʷ', 'tʲ',\n",
    "              'ɡ', 'ɡʷ', 'ɡʲ',\n",
    "              'k', \"k'\", 'kː', \"k'ː\", 'kʷ', 'kʷ', \"k'ʷ\", 'kːʷ', \"k'ːʷ\", 'kʲ', \"kʲ'\", 'kʲː',\n",
    "              'ɢ','ɢʷ', \n",
    "              'q', \"q'\", 'qː', \"q'ː\", 'qʷ', \"q'ʷ\", 'qːʷ', \"q'ːʷ\",\n",
    "              'ʔ', 'ʔʷ', \n",
    "              'dz',\n",
    "              'ts', 'tsː', \"ts'\", \"tsː'\", \"ts'ː\", 'tsʷ', \"ts'ʷ\", \"ts'ːʷ\",\n",
    "              'dʒ', 'dʒʷ', 'tʃ', 'tʃː', \"tʃ'\", \"tʃː'\", \"tʃ'ː\", 'tʃʷ', \"tʃ'ʷ\", 'tʃːʷ', \"tʃ'ːʷ\",\n",
    "              'tɬ', \"tɬ'\", 'tɬː', \"tɬː'\", \"tɬ'ː\", 'tɬʷ', \"tɬ'ʷ\", 'tɬːʷ', \"tɬ'ːʷ\",\n",
    "              'qχ', \"qχ'\", 'qχː', \"qχː'\", 'qχʷ', \"qχ'ʷ\",\n",
    "              'f', \n",
    "              'z', 'zː', 'zʷ',\n",
    "              's', 'sː', \"s'\", \"s'ː\", 'sʷ', \"s'ʷ\", 'sːʷ', \"s'ːʷ\",\n",
    "              'ʒ', 'ʒʷ',\n",
    "              'ʃ', 'ʃː', \"ʃ'ː\", 'ʃʷ', 'ʃːʷ', \"ʃ'ːʷ\",\n",
    "              'ɬ', 'ɬː', 'ɬʷ', 'ɬːʷ', 'ɬʲ',\n",
    "              'x', 'xː', 'xʷ', 'xːʷ', 'xʲ', \n",
    "              'ʁ', 'ʁʷ',\n",
    "              'χ', 'χː', 'χʷ', 'χːʷ',\n",
    "              'ʕ', 'ʕʷ',\n",
    "              'ħ', 'ħː', 'ħʷ',\n",
    "              'h', 'hʷ',\n",
    "              'm', 'mː',\n",
    "              'w',\n",
    "              'n', 'nː', 'nʷ', 'nʲ',\n",
    "              'r', 'rʷ', 'rʲ', \n",
    "              'l', 'lː', 'lʷ', 'lʲ',\n",
    "              'j']\n",
    "\n",
    "vowels = ['a', 'aː','ˌa', 'ˌaː', \"a'\", 'ã', 'ãː',\n",
    "          'i', 'ˌi', 'iː', 'ĩ', 'ĩː',\n",
    "          'e', 'ˌe', 'eː', 'ẽ', 'ẽː',\n",
    "          'o', 'ˌo', 'oː', 'õ', 'õː',\n",
    "          'u', 'uː', 'ˌu', \"u'\", 'ũ', 'ũː']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for the level of phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('andic_dicts.csv', encoding='utf8') as csv_database:\n",
    "    database = csv.DictReader(csv_database, delimiter=',')\n",
    "\n",
    "    i = 0\n",
    "    phon_dict = {}\n",
    "\n",
    "    for row in database:\n",
    "        if row['glottocode'] != languages[i]:\n",
    "            with open(languages[i] + 'phonemes.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(phon_dict, f, ensure_ascii=False, indent=2)\n",
    "                phon_dict = {}\n",
    "                i += 1\n",
    "        phonemes = row['ipa'].split('-')\n",
    "        for sound in phonemes:\n",
    "            sound = sound.replace('(', '')\n",
    "            sound = sound.replace(')', '')\n",
    "            if len(sound) == 1:\n",
    "                if phon_dict.get(sound):\n",
    "                    phon_dict[sound] += 1\n",
    "                else:\n",
    "                    phon_dict[sound] = 1\n",
    "            if len(sound) > 1:\n",
    "                sound2 = sound.split(' ')\n",
    "                for s in sound2:\n",
    "                    if s[0] == \"'\":\n",
    "                        s = s[1:]\n",
    "                    if phon_dict.get(s):\n",
    "                        phon_dict[s] += 1\n",
    "                    else:\n",
    "                        phon_dict[s] = 1\n",
    "    with open(languages[i] + 'phonemes.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(phon_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for the level of functional phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('andic_dicts.csv', encoding='utf8') as csv_database:\n",
    "    database = csv.DictReader(csv_database, delimiter=',')\n",
    "    \n",
    "    i = 0\n",
    "    place_dict = {}\n",
    "\n",
    "    for row in database:\n",
    "        if row['glottocode'] != languages[i]:\n",
    "            for k, v in place_dict.items():\n",
    "                v = set(v)\n",
    "                place_dict[k] = list(v)\n",
    "            with open(languages[i] + 'places.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(place_dict, f, ensure_ascii=False, indent=2)\n",
    "                place_dict = {}\n",
    "                i += 1\n",
    "        trans = row['ipa']\n",
    "        if len(trans.split(' ')) == 1:\n",
    "            trans = trans.split('-')\n",
    "            \n",
    "            if place_dict.get(trans[0]):\n",
    "                place_dict[trans[0]].append('first')\n",
    "            else:\n",
    "                place_dict[trans[0]] = ['first']\n",
    "                \n",
    "            if len(trans) > 1:\n",
    "                if place_dict.get(trans[1]):\n",
    "                    place_dict[trans[1]].append('second')\n",
    "                else:\n",
    "                    place_dict[trans[1]] = ['second']\n",
    "                                        \n",
    "                if place_dict.get(trans[-2]):\n",
    "                    place_dict[trans[-2]].append('penultimate')\n",
    "                else:\n",
    "                    place_dict[trans[-2]] = ['penultimate']\n",
    "                \n",
    "                if place_dict.get(trans[-1]):\n",
    "                    place_dict[trans[-1]].append('last')\n",
    "                else:\n",
    "                    place_dict[trans[-1]] = ['last']\n",
    "\n",
    "        else:\n",
    "            for word in trans.split(' '):\n",
    "                word = word.split('-')\n",
    "\n",
    "                if place_dict.get(word[0]):\n",
    "                    place_dict[word[0]].append('first')\n",
    "                else:\n",
    "                    place_dict[word[0]] = ['first']\n",
    "                \n",
    "                if len(word) > 1:\n",
    "                    if place_dict.get(word[1]):\n",
    "                        place_dict[word[1]].append('second')\n",
    "                    else:\n",
    "                        place_dict[word[1]] = ['second']\n",
    "                                        \n",
    "                    if place_dict.get(word[-2]):\n",
    "                        place_dict[word[-2]].append('penultimate')\n",
    "                    else:\n",
    "                        place_dict[word[-2]] = ['penultimate']\n",
    "                \n",
    "                    if place_dict.get(word[-1]):\n",
    "                        place_dict[word[-1]].append('last')\n",
    "                    else:\n",
    "                        place_dict[word[-1]] = ['last']\n",
    "                    \n",
    "    for k, v in place_dict.items():\n",
    "        v = set(v)\n",
    "        place_dict[k] = list(v)\n",
    "    with open(languages[i] + 'places.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(place_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison on the Level of Phonetics\n",
    "Firstly, we will compare sounds on the level of phonetics. For this purpose, we create a dictionary where the keys are languages, and the values are dictionaries with two keys: consonants and vowels where the values are lists of consonants and vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phonemes = {}\n",
    "\n",
    "for language in languages:\n",
    "    cons = []\n",
    "    vow = []\n",
    "    with open(language + 'phonemes.json', encoding='utf8') as f:\n",
    "        ph_dct = json.load(f)\n",
    "    for sound, amount in ph_dct.items():\n",
    "        if sound in consonants:\n",
    "            cons.append(sound)\n",
    "        elif sound in vowels:\n",
    "            vow.append(sound)\n",
    "    all_phonemes[language] = {'consonants': cons, 'vowels': vow}\n",
    "\n",
    "with open('phonemes by language.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(all_phonemes, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are making list of number of languages in which every phoneme appears just in case to look at the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 9, 'd': 9, 'ʒ': 9, 'r': 9, 'χ': 9, 'ʃ': 9, 'w': 9, 'ɬ': 9, 'l': 9, 'j': 9, \"k'\": 9, 's': 9, 'ʁ': 9, 'z': 9, 'h': 9, 'ɡʷ': 9, 'k': 9, 'ɡ': 9, 'n': 9, 't': 9, 'm': 9, \"tʃ'\": 9, 'sː': 9, \"q'\": 9, 'ɬː': 9, 'ʔ': 9, 'χː': 9, 'tʃ': 9, \"t'\": 9, 'p': 9, 'ts': 9, \"k'ʷ\": 9, 'ʃː': 9, 'ʕ': 9, 'q': 9, \"ts'\": 9, 'tʃː': 9, 'kʷ': 9, 'tɬ': 8, 'ħ': 8, 'χʷ': 8, 'ʁʷ': 8, 'χːʷ': 8, 'qʷ': 8, 'tʃʷ': 8, \"t'ʷ\": 8, \"q'ʷ\": 8, 'x': 8, 'dʒ': 7, \"p'\": 7, 'tsː': 7, \"tɬ'\": 7, \"tʃ'ː\": 7, 'sʷ': 7, 'kː': 7, 'hʷ': 7, \"tʃ'ʷ\": 7, 'zʷ': 7, 'dː': 7, 'ʒʷ': 6, 'dʷ': 6, \"k'ː\": 6, \"ts'ː\": 6, \"k'ːʷ\": 6, 'sːʷ': 6, 'tʷ': 6, \"tɬ'ʷ\": 6, 'ʃːʷ': 6, 'xʷ': 6, 'ħʷ': 5, 'tɬʷ': 5, 'lː': 4, 'mː': 4, 'tsːʷ': 4, \"ts'ːʷ\": 4, \"ts'ʷ\": 4, 'kʲ': 4, 'tsʷ': 4, 'kːʷ': 4, 'ʃʷ': 3, 'xː': 3, 'ɬːʷ': 3, \"tʃ'ːʷ\": 3, 'ʔʷ': 3, 'lʲ': 3, 'bː': 3, \"kʲ'\": 3, 'nː': 3, 'tɬː': 2, \"q'ː\": 2, 'xːʷ': 2, 'ɬʷ': 2, 'ɢ': 2, 'tː': 2, 'pː': 2, \"s'ː\": 2, \"s'\": 2, \"t'ː\": 2, 'rʷ': 2, 'nʷ': 2, 'lʷ': 2, 'zː': 2, 'ɡʲ': 2, 'xʲ': 2, 'kʲː': 2, 'tʃːʷ': 2, 'bʷ': 2, 'qː': 1, \"tɬ'ː\": 1, \"tɬ'ːʷ\": 1, \"q'ːʷ\": 1, 'qːʷ': 1, 'ʕʷ': 1, 'ɢʷ': 1, \"ʃ'ː\": 1, \"ʃ'ːʷ\": 1, \"s'ːʷ\": 1, 'nʲ': 1, 'rʲ': 1, 'f': 1, 'tʲ': 1, 'dʒʷ': 1, \"qχ'\": 1, 'qχʷ': 1, 'qχ': 1, 'dz': 1, \"qχ'ʷ\": 1, \"s'ʷ\": 1, 'ħː': 1, 'tɬːʷ': 1, 'ɬʲ': 1, 'dːʷ': 1}\n",
      "{'a': 9, 'i': 9, 'e': 9, 'u': 9, 'o': 9, 'ã': 8, 'ĩ': 8, 'ũ': 8, 'oː': 7, 'eː': 7, 'aː': 7, 'ẽ': 7, 'ãː': 7, 'iː': 6, 'uː': 5, 'õ': 5, 'ĩː': 4, 'õː': 4, 'ẽː': 3, 'ũː': 3, 'ˌa': 2, 'ˌe': 2, 'ˌi': 2, 'ˌo': 2, 'ˌu': 2, \"a'\": 1, \"u'\": 1, 'ˌaː': 1}\n"
     ]
    }
   ],
   "source": [
    "c_num = {}\n",
    "v_num = {}\n",
    "c_num_sort = {}\n",
    "v_num_sort = {}\n",
    "\n",
    "with open('phonemes by language.json', encoding='utf8') as f:\n",
    "    dct = json.load(f)\n",
    "    \n",
    "for lang in dct.keys():\n",
    "    for kind, sound in dct[lang].items():\n",
    "        if kind == 'consonants':\n",
    "            for s in sound:\n",
    "                if c_num.get(s):\n",
    "                    c_num[s] += 1\n",
    "                else:\n",
    "                    c_num[s] = 1\n",
    "        if kind == 'vowels':\n",
    "            for s in sound:\n",
    "                if v_num.get(s):\n",
    "                    v_num[s] += 1\n",
    "                else:\n",
    "                    v_num[s] = 1\n",
    "                    \n",
    "sort = sorted(c_num, key=c_num.get, reverse=True)\n",
    "for v in sort:\n",
    "    c_num_sort[v] = c_num[v]\n",
    "    \n",
    "sort = sorted(v_num, key=v_num.get, reverse=True)\n",
    "for v in sort:\n",
    "    v_num_sort[v] = v_num[v]\n",
    "    \n",
    "print(c_num_sort)\n",
    "print(v_num_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we count the number of phonemes in each language to figure out what languages are most complex at the level of phonetics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akhv1239 consonants: 87 vowels 18\n",
      "andi1255 consonants: 68 vowels 5\n",
      "bagv1239 consonants: 85 vowels 18\n",
      "botl1242 consonants: 73 vowels 16\n",
      "cham1309 consonants: 89 vowels 25\n",
      "ghod1238 consonants: 68 vowels 14\n",
      "kara1474 consonants: 80 vowels 17\n",
      "tind1238 consonants: 90 vowels 25\n",
      "toki1238 consonants: 51 vowels 9\n"
     ]
    }
   ],
   "source": [
    "with open('phonemes by language.json', encoding='utf8') as f:\n",
    "    phon = json.load(f)\n",
    "    \n",
    "for language in phon.keys():\n",
    "    c = len(phon[language]['consonants'])\n",
    "    v = len(phon[language]['vowels'])\n",
    "    print(language, 'consonants:', c, 'vowels', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison on the Level of Functional Phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_all = []\n",
    "vow_all = []\n",
    "cons_all_dict = {}\n",
    "vow_all_dict = {}\n",
    "\n",
    "for k, v in c_num_sort.items():\n",
    "    if v == 9:\n",
    "        cons_all.append(k)\n",
    "for k, v in v_num_sort.items():\n",
    "    if v == 9:\n",
    "        vow_all.append(k)\n",
    "\n",
    "for lang in languages:\n",
    "    with open(lang + 'places.json', encoding='utf8') as f:\n",
    "        phon_places = json.load(f)\n",
    "        \n",
    "    for c in cons_all:\n",
    "        if not phon_places.get(c):\n",
    "            if cons_all_dict[c].get('middle'):\n",
    "                cons_all_dict[c]['middle'].append(lang)\n",
    "            else:\n",
    "                cons_all_dict[c]['middle'] = [lang]\n",
    "            continue\n",
    "            \n",
    "        places = phon_places[c]\n",
    "        if not cons_all_dict.get(c):\n",
    "            cons_all_dict[c] = {}\n",
    "        for place in places:\n",
    "            if cons_all_dict[c].get(place):\n",
    "                cons_all_dict[c][place].append(lang)\n",
    "            else:\n",
    "                cons_all_dict[c][place] = [lang]\n",
    "                \n",
    "    for v in vow_all:\n",
    "        places = phon_places[v]\n",
    "        if not vow_all_dict.get(v):\n",
    "            vow_all_dict[v] = {}\n",
    "        for place in places:\n",
    "            if vow_all_dict[v].get(place):\n",
    "                vow_all_dict[v][place].append(lang)\n",
    "            else:\n",
    "                vow_all_dict[v][place] = [lang]\n",
    "                \n",
    "with open('consonants places.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(cons_all_dict, f, ensure_ascii=False, indent=2)\n",
    "with open('vowels places.json', 'w', encoding='utf8') as f:\n",
    "    json.dump(vow_all_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a second 9\n",
      "a first 9\n",
      "a penultimate 9\n",
      "a last 9\n",
      "i second 9\n",
      "i first 9\n",
      "i penultimate 9\n",
      "i last 9\n",
      "e second 9\n",
      "e first 9\n",
      "e penultimate 8\n",
      "e last 9\n",
      "u second 9\n",
      "u first 9\n",
      "u penultimate 9\n",
      "u last 9\n",
      "o second 9\n",
      "o first 9\n",
      "o penultimate 9\n",
      "o last 9\n"
     ]
    }
   ],
   "source": [
    "for k1,v1 in vow_all_dict.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        print(k1, k2, len(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "d last ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʒ second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʒ first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʒ last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474']\n",
      "χ last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "ʃ second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʃ first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʃ penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʃ last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "w first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "w penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɬ last ['akhv1239', 'bagv1239', 'cham1309']\n",
      "l first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "j second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "j first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "k' second ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'tind1238']\n",
      "k' last ['bagv1239', 'botl1242', 'cham1309', 'kara1474']\n",
      "s penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "s last ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʁ second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʁ penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʁ last ['bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "z second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "z first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "z last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "h last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɡʷ second ['akhv1239']\n",
      "ɡʷ first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɡʷ penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɡʷ last ['bagv1239', 'cham1309']\n",
      "ɡʷ middle ['toki1238']\n",
      "k second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "k last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɡ second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɡ last ['bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "n second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "n first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "t last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "m penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "m last ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "tʃ' second ['akhv1239', 'botl1242', 'cham1309', 'kara1474', 'tind1238', 'toki1238']\n",
      "tʃ' last ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474']\n",
      "sː second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "sː first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "sː last ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "q' second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "q' last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɬː second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'kara1474', 'tind1238']\n",
      "ɬː first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɬː penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ɬː last ['bagv1239', 'cham1309']\n",
      "ɬː middle ['toki1238']\n",
      "ʔ second ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'kara1474', 'tind1238', 'toki1238']\n",
      "ʔ first ['akhv1239', 'botl1242', 'kara1474']\n",
      "ʔ last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'kara1474']\n",
      "χː first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "χː penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "χː last ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "tʃ second ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "tʃ last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474']\n",
      "t' second ['akhv1239', 'andi1255', 'bagv1239', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "t' penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "t' last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "p first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "p last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ts second ['akhv1239', 'andi1255', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ts penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ts last ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "k'ʷ second ['akhv1239', 'bagv1239', 'botl1242', 'cham1309']\n",
      "k'ʷ first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "k'ʷ last ['bagv1239', 'botl1242', 'cham1309']\n",
      "ʃː last ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'toki1238']\n",
      "ʃː second ['andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ʕ first ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "ʕ penultimate ['akhv1239', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "ʕ middle ['andi1255']\n",
      "ʕ second ['bagv1239', 'cham1309', 'ghod1238']\n",
      "ʕ last ['bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "q last ['bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474']\n",
      "ts' second ['akhv1239', 'botl1242', 'cham1309', 'tind1238']\n",
      "ts' penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "ts' last ['bagv1239', 'botl1242', 'cham1309', 'kara1474']\n",
      "tʃː second ['akhv1239', 'andi1255', 'botl1242', 'ghod1238', 'kara1474', 'tind1238']\n",
      "tʃː first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'ghod1238', 'kara1474', 'tind1238']\n",
      "tʃː penultimate ['akhv1239', 'andi1255', 'botl1242', 'ghod1238', 'kara1474', 'tind1238', 'toki1238']\n",
      "tʃː last ['botl1242', 'ghod1238', 'kara1474']\n",
      "tʃː middle ['cham1309']\n",
      "kʷ first ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "kʷ penultimate ['akhv1239', 'andi1255', 'bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "kʷ second ['bagv1239', 'botl1242', 'cham1309', 'ghod1238', 'kara1474', 'tind1238']\n",
      "kʷ last ['bagv1239', 'cham1309']\n",
      "kʷ middle ['toki1238']\n"
     ]
    }
   ],
   "source": [
    "for k1,v1 in cons_all_dict.items():\n",
    "    for k2,v2 in v1.items():\n",
    "        if len(v2) < 9:\n",
    "            print(k1, k2, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dc2e76d637f38cb534d007662ee080514e23b3d0d0dd6e2f651136baa4a9222"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
